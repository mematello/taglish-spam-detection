Hereâ€™s a **clean and structured prompt** you can give to Claude (or any coding assistant) so it clearly understands the project setup and what needs to be built:

---

**Prompt for Claude:**

You are helping me build a **Web UI** for my `taglish-spam-detection` project.
Below is the complete project structure and requirements.

---

### ğŸ“‚ Project Folder Structure

The root folder is **`taglish-spam-detection`** and currently contains:

```
taglish-spam-detection/
â”‚
â”œâ”€ dataset/                  # Dataset files (e.g. final_spam_ham_dataset.csv)
â”‚
â”œâ”€ models/                   # All models are inside here
â”‚   â”œâ”€ lstm/
â”‚   â”‚   â”œâ”€ train_model.py    # trains LSTM model and saves .pkl
â”‚   â”‚   â””â”€ test_model.py     # loads saved model and runs predictions
â”‚   â”‚
â”‚   â”œâ”€ logistic_regression/
â”‚   â”‚   â”œâ”€ train_model.py
â”‚   â”‚   â””â”€ test_model.py
â”‚   â”‚
â”‚   â””â”€ xlm/                  # (XLM-Roberta based) â€“ still being finalized
â”‚       â”œâ”€ train_model.py
â”‚       â””â”€ test_model.py
â”‚
â”œâ”€ web_ui/                   # This is where the Web App will live
â”‚
â”œâ”€ venv/                      # Python virtual environment
â”‚
â”œâ”€ .gitignore
â”œâ”€ README.md
â””â”€ requirements.txt
```

---

### ğŸ’¡ Current Models

* **LSTM** (already working)
* **TFIDF + Logistic Regression** (working)
* **XLM-Roberta** (in progress)

Each model has:

1. `train_model.py` â€“ trains the model and saves a `.pkl` file inside the same model folder.
2. `test_model.py` â€“ loads the trained `.pkl` file and predicts spam/ham for a given text.

---

### ğŸŒ Task: Build a Web UI

Create a **single web application** (inside `web_ui/`) where the user can:

1. **Upload or type a message** to classify as spam/ham.
2. **Select a model** (dropdown or buttons):

   * LSTM
   * TFIDF + Logistic Regression
   * XLM-Roberta
3. View the **prediction result** and confidence score.
4. (Optional) Allow uploading a CSV of multiple messages to batch classify.

---

### ğŸ”‘ Technical Requirements

* Use **Streamlit** or **Flask** (you decide, but Streamlit is simpler).
* The app should dynamically load the correct `.pkl` file depending on the chosen model.
* Show model information (e.g., accuracy, training date) if available.
* Make sure the UI is clean, responsive, and easy to use.

---

### ğŸ“ Output Expected

1. Inside `web_ui/`, create the main app file (e.g., `app.py` for Flask or `streamlit_app.py` for Streamlit).
2. Provide instructions on:

   * How to install requirements (`requirements.txt`).
   * How to run the web UI.
   * How to add new models in the future.
3. Example of how the LSTM model is loaded (as a reference) and used for predictions.

---

**Goal:**
Deliver a fully working web interface that allows switching between the **LSTM**, **Logistic Regression**, and **XLM-Roberta** models for Taglish spam detection.

---
